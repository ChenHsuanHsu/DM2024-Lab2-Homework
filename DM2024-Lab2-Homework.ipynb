{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 許宸瑄\n",
    "\n",
    "Student ID: B10209001\n",
    "\n",
    "GitHub ID: ChenHsuanHsu\n",
    "\n",
    "Kaggle name: kyonatsuki\n",
    "\n",
    "Kaggle private scoreboard snapshot: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Scoreboard](scoreboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First part of my homework is done in DM2024-Lab2-Master.ipynb under DM2024-Lab2-Master file [open Notebook](https://github.com/ChenHsuanHsu/DM2024-Lab2-Master/blob/main/DM2024-Lab2-Master.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second part of my homework is Kaggle.ipynb under same files as this text\n",
    "[open Notebook](https://github.com/ChenHsuanHsu/DM2024-Lab2-Homework/blob/main/Kaggle.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Third: A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "撰寫一份您參加比賽時開發模型的報告（可以使用並註解代碼）。此報告應包含您的數據預處理步驟、特徵工程步驟以及對模型的解釋。您還可以提及您嘗試過的不同方法以及獲得的見解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取json所有欄位，存成所有tweets的dataframe。再將其與情緒分類檔案及身份識別文件（訓練或測試資料）合併。  \n",
    "Read all fields from the JSON file and store them as a DataFrame containing all tweets. Then, merge this DataFrame with the emotion classification file and the identity file (indicating whether the data is for training or testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 存储提取数据的列表\n",
    "tweets_data = []\n",
    "\n",
    "# 读取 JSON 文件\n",
    "with open('dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # 解析 JSON 每行\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # 提取字段\n",
    "            tweet_id = tweet[\"_source\"][\"tweet\"].get(\"tweet_id\")\n",
    "            text = tweet[\"_source\"][\"tweet\"].get(\"text\")\n",
    "            hashtags = tweet[\"_source\"][\"tweet\"].get(\"hashtags\", [])\n",
    "            crawldate = tweet.get(\"_crawldate\")\n",
    "            score = tweet.get(\"_score\")\n",
    "            index = tweet.get(\"_index\")\n",
    "            doc_type = tweet.get(\"_type\")\n",
    "            \n",
    "            # 衍生字段\n",
    "            hashtag_count = len(hashtags)\n",
    "            text_length = len(text) if text else 0\n",
    "            contains_keyword = \"<LH>\" in text if text else False\n",
    "\n",
    "            # 将提取的字段存入字典，添加到列表\n",
    "            tweets_data.append({\n",
    "                \"tweet_id\": tweet_id,\n",
    "                \"text\": text,\n",
    "                \"hashtags\": hashtags,\n",
    "                \"crawldate\": crawldate,\n",
    "                \"_score\": score,\n",
    "                \"_index\": index,\n",
    "                \"_type\": doc_type,\n",
    "                \"hashtag_count\": hashtag_count,\n",
    "                \"text_length\": text_length,\n",
    "                \"contains_keyword\": contains_keyword\n",
    "            })\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(tweets_data)\n",
    "\n",
    "classify = pd.read_csv('dm-2024-isa-5810-lab-2-homework/data_identification.csv')  # 包含 tweet_id 和 identification\n",
    "emotion = pd.read_csv('dm-2024-isa-5810-lab-2-homework/emotion.csv')  # 包含 tweet_id 和 emotion\n",
    "data = pd.merge(df, classify, on='tweet_id', how='inner')\n",
    "data = pd.merge(data, emotion, on='tweet_id', how='outer')\n",
    "# data # 將情緒特徵及資料分類欄位加入相同dataframe\n",
    "\n",
    "# 將 data_identification 中 identification 欄位值為 'train' 的選出來作為訓練集\n",
    "train_data = data[data['identification'] == 'train']\n",
    "\n",
    "# 將 identification 欄位值為 'test' 的選出來作為測試集\n",
    "test_data = data[data['identification'] == 'test']\n",
    "\n",
    "# 所有情感emotion in emotion.csv\n",
    "emotions = data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. feature enginering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize the text in each tweets 將文字資料轉成向量形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_data['text'])\n",
    "\n",
    "X_train = BOW_500.transform(train_data['text'])\n",
    "\n",
    "y_train = train_data['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_data['text'])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 初始化 TfidfVectorizer，并限制特征数为 1000\n",
    "tfidf_vect = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# 使用 TF-IDF 向量化器进行训练集和测试集的向量化\n",
    "X_train = tfidf_vect.fit_transform(train_data[\"text\"])\n",
    "X_test = tfidf_vect.transform(test_data[\"text\"])\n",
    "\n",
    "# 获取特征名称列表\n",
    "feature_names = tfidf_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "test_data = pd.read_pickle('output_1/test_data.pkl')\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練多層感知機模型\n",
    "mlp_clf = MLPClassifier(random_state=42, max_iter=500)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = mlp_clf.predict(X_test)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nearist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/lx/4bn5cmyn63b1p7gtb6m71jch0000gn/T/ipykernel_59297/2295660456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     19\u001b[0m \u001b[0;31m# 進行預測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 20\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[0;31m# 保存結果至 CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n",
      "\u001b[1;32m    257\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    258\u001b[0m             ):\n",
      "\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    261\u001b[0m                     return np.stack(\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    365\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n",
      "\u001b[1;32m    884\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 886\u001b[0;31m             chunked_results = list(\n",
      "\u001b[0m\u001b[1;32m    887\u001b[0m                 pairwise_distances_chunked(\n",
      "\u001b[1;32m    888\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n",
      "\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2171\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 2172\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   2173\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n",
      "\u001b[1;32m   2174\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    211\u001b[0m                     )\n",
      "\u001b[1;32m    212\u001b[0m                 ):\n",
      "\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n",
      "\u001b[1;32m   2373\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 2375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   2376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n",
      "\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1892\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1893\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1895\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    184\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    188\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n",
      "\u001b[1;32m    370\u001b[0m             )\n",
      "\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n",
      "\u001b[1;32m    405\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    406\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    409\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n",
      "\u001b[1;32m    203\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    204\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    207\u001b[0m     if (\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n",
      "\u001b[1;32m    676\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n",
      "\u001b[1;32m    677\u001b[0m                              \"use '*' instead\")\n",
      "\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n",
      "\u001b[1;32m    587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    588\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 589\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    591\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n",
      "\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    537\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matmat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 538\u001b[0;31m         fn(M, N, np.asarray(self.indptr, dtype=idx_dtype),\n",
      "\u001b[0m\u001b[1;32m    539\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    540\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "test_data = pd.read_pickle('output_1/test_data.pkl')\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練 KNN 模型\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Prediction results saved to prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "test_data = pd.read_pickle('output_1/test_data.pkl')\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練邏輯迴歸模型\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "test_data = pd.read_pickle('output_1/test_data.pkl')\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練 CatBoost 模型\n",
    "catboost_clf = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 關閉訓練輸出\n",
    "catboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = catboost_clf.predict(X_test)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [05:31:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test =X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練 XGBoost 模型\n",
    "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results saved to prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 將數字標籤轉換回原始情緒標籤\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# 輸出解碼後的情緒標籤\n",
    "print(y_pred_decoded)\n",
    "len(y_pred_decoded)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data[\"tweet_id\"],\n",
    "    'predicted_emotion': y_pred_decoded\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 將特徵轉換為浮點型\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 初始化並訓練隨機森林模型\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算預測精度\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': X_test['tweet_id'],\n",
    "    'predicted_emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results_randomforest.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results_randomforest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 優化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.595803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.634976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.524052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.542838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.684757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.567021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.598216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.605967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.591571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.587885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.529498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.527066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.555402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.653103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.558244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.554280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.522190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.532491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.520160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.495403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.563810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.569027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.509650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.568491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.549481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.533673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.525391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.546909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.529101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.564312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.556645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.557801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.501839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.504018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.490121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.570200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.566748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.568635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.538474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.496511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.592141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.503624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.782462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.635629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.544401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.665625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.554221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.669591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.566472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.514329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.526236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.528304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.551755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.605973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.538438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.555137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.555812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.558097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.564373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.615833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.542139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.615714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.528814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.541374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.591844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.479855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.573155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.548376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.494021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.503626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.509670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.512049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.527138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.566838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.488322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.490193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.529024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.577977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.489349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.524416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.524523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.538139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.527796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.564048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.538920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.577622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.666229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.552211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.464433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.515448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.501155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.549911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.537109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.524452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.546257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.471412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.478226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.553489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.463654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.560882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.489588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.532974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.543309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.577652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.534152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.501290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.530703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.516644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.507855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.525147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.561829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.521344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.508852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.577771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.484872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.513676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.544754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.492769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.540299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.550284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.574757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.510644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.564988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.538678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.517307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.482357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.518249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.546064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.542640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.553474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.512077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.477159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.548300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.543359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.547864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.527772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.570575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.481418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.488514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.520843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.536810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.533763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.520733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.555435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.527118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.562272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.547833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.543957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.535166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.499014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.474359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.524800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.563612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.548476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.565376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.539145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.526883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765960\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037006\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.613146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 970375, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765954\n",
      "[LightGBM] [Info] Start training from score -2.347947\n",
      "[LightGBM] [Info] Start training from score -3.124280\n",
      "[LightGBM] [Info] Start training from score -1.037009\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396873\n",
      "[LightGBM] [Info] Start training from score -1.957811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.617398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 970376, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597600\n",
      "[LightGBM] [Info] Start training from score -1.765955\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037010\n",
      "[LightGBM] [Info] Start training from score -2.018197\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/lx/4bn5cmyn63b1p7gtb6m71jch0000gn/T/ipykernel_30166/3581439895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[0;31m# 使用最佳參數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1471\u001b[0m                 )\n",
      "\u001b[1;32m   1472\u001b[0m             ):\n",
      "\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n",
      "\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[1;32m    963\u001b[0m                     )\n",
      "\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n",
      "\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     73\u001b[0m         )\n",
      "\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n",
      "\u001b[1;32m    886\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    890\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n",
      "\u001b[1;32m   1282\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1284\u001b[0;31m         super().fit(\n",
      "\u001b[0m\u001b[1;32m   1285\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1286\u001b[0m             \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n",
      "\u001b[1;32m    953\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 955\u001b[0;31m         self._Booster = train(\n",
      "\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    957\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n",
      "\u001b[1;32m    305\u001b[0m             )\n",
      "\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n",
      "\u001b[1;32m   4134\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot update due to null objective function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4135\u001b[0m             _safe_call(\n",
      "\u001b[0;32m-> 4136\u001b[0;31m                 _LIB.LGBM_BoosterUpdateOneIter(\n",
      "\u001b[0m\u001b[1;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4138\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定義超參數範圍\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# 使用 GridSearchCV 進行參數搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LGBMClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 使用最佳參數\n",
    "best_lgbm_clf = grid_search.best_estimator_\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# 在最佳參數下訓練模型並預測\n",
    "best_lgbm_clf.fit(X_train, y_train)\n",
    "y_pred = best_lgbm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results saved to prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'predicted_emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.9/site-packages (4.5.0)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.12.0)\n",
      "Using cached xgboost-2.1.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.1 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 定义 LightGBM 模型\n",
    "model = LGBMClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 测试集预测\n",
    "y_test_pred_lgbm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_pickle('output_1/test_data.pkl')\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "# 初始化並訓練支持向量機模型\n",
    "svm_clf = SVC(random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# 保存結果至 CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'predicted_emotion': y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "[first submission](https://github.com/ChenHsuanHsu/DM2024-Lab2-Homework/blob/main/first_try.ipynb)\n",
    "\n",
    "feature enginering : **Bag of Words**  \n",
    "model : **DecisionTree**\n",
    "\n",
    ">score : 0.28376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "[second submission](https://github.com/ChenHsuanHsu/DM2024-Lab2-Homework/blob/main/second_try.ipynb)\n",
    "\n",
    "feature enginering : **Bag of Words**  \n",
    "model : **DecisionTree**\n",
    "\n",
    "problem: Too much different data, fail to submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 & 4 attempt\n",
    "[third submission](https://github.com/ChenHsuanHsu/DM2024-Lab2-Homework/blob/main/third_try.ipynb)\n",
    "\n",
    "feature enginering : **Bag of Words**  \n",
    "model3 : **LightGBM**  \n",
    "  \n",
    "> score:0.35555\n",
    "\n",
    "model4 : **XGBoost**  \n",
    "> score:0.20148  \n",
    "\n",
    "model5 : **LogisticRegression**  \n",
    "> score:0.33557   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 attempt  \n",
    "\n",
    "model6 : **LightGBM**  \n",
    "> score:0.37052  \n",
    "\n",
    "\n",
    "\n",
    "other attempt : voting regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMLab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
