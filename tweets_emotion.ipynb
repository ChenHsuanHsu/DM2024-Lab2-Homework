{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 500)\n",
      "y_train.shape:  (1455563,)\n",
      "X_test.shape:  (411972, 500)\n",
      "y_test.shape:  (411972,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 .pkl 文件\n",
    "X_train = pd.read_pickle('output_3/X_train.pkl')\n",
    "y_train = pd.read_pickle('output_3/y_train.pkl')\n",
    "X_test = pd.read_pickle('output_3/X_test.pkl')\n",
    "y_test = pd.read_pickle('output_3/y_test.pkl')\n",
    "\n",
    "train_path ='output_1/train_data.pkl'\n",
    "test_path ='output_1/test_data.pkl'\n",
    "train_data = pd.read_pickle(train_path)\n",
    "test_data = pd.read_pickle(test_path)\n",
    "\n",
    "# 檢查數據\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "# y_test = label_encode(label_encoder, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 06:35:58.021262: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-18 06:35:58.021310: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 06:36:00.307882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1455563,8]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-11-18 06:36:00.308165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1455563,8]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-11-18 06:36:00.673372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-18 06:36:00.723351: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62574/181946 [=========>....................] - ETA: 12:14:02 - loss: 1.5060 - accuracy: 0.4531"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "from keras.callbacks import CSVLogger\n",
    "import gc\n",
    "\n",
    "\n",
    "# 定義模型\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = len(label_encoder.classes_)\n",
    "\n",
    "model_input = Input(shape=(input_shape,))\n",
    "X = model_input\n",
    "\n",
    "#X_W1 = Dense(units=16)(X)  # 減少隱藏層單元數量\n",
    "#H1 = ReLU()(X_W1)\n",
    "\n",
    "H1_W2 = Dense(units=output_shape)(X)\n",
    "H2 = Softmax()(H1_W2)\n",
    "\n",
    "model_output = H2\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# 使用混合精度編譯模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 訓練日誌\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# 訓練\n",
    "epochs = 50  # 減少訓練次數\n",
    "batch_size = 8  # 減少批次大小\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 06:35:41.178207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lx/4bn5cmyn63b1p7gtb6m71jch0000gn/T/ipykernel_15865/2535745925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 定義模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Softmax\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# 定義模型\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = len(label_encoder.classes_)\n",
    "\n",
    "# Input layer\n",
    "model_input = Input(shape=(input_shape,))\n",
    "X = model_input\n",
    "\n",
    "# 直接接輸出層並使用 Softmax\n",
    "X_W1 = Dense(units=output_shape)(X)\n",
    "model_output = Softmax()(X_W1)\n",
    "\n",
    "# 建立模型\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 訓練日誌\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# 訓練參數\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# 開始訓練\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from index 100 to 110: ['asked' 'asking' 'ass' 'at' 'august' 'away' 'awesome' 'awkward' 'baby'\n",
      " 'back']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 初始化 TfidfVectorizer，并限制特征数为 1000\n",
    "tfidf_vect = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# 使用 TF-IDF 向量化器进行训练集和测试集的向量化\n",
    "train_tfidf = tfidf_vect.fit_transform(train_data[\"text\"])\n",
    "test_tfidf = tfidf_vect.transform(test_data[\"text\"])\n",
    "\n",
    "# 获取特征名称列表\n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "# 显示索引 100 到 110 的特征名称\n",
    "selected_features = feature_names[100:110]\n",
    "print(\"Features from index 100 to 110:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 10:02:29.777587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lx/4bn5cmyn63b1p7gtb6m71jch0000gn/T/ipykernel_70899/3316266337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m## check dimension is a good habbit 確認數據正確性\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train.shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train.shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_test.shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "y_train = train_data['emotion'] # 情感標籤\n",
    "y_test = test_data['emotion']\n",
    "\n",
    "## check dimension is a good habbit 確認數據正確性\n",
    "print('X_train.shape: ', train_tfidf.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', test_tfidf.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
