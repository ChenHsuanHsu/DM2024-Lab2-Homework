{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change environment when running in different terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXEC_ENV_ENUM(Enum):\n",
    "    COLAB = 1\n",
    "    KAGGLE = 2\n",
    "    LOCAL = 3\n",
    "\n",
    "\"\"\"\n",
    "丟到 kaggle 要改的地方\n",
    "\"\"\"\n",
    "# EXEC_ENV = EXEC_ENV_ENUM.COLAB\n",
    "# EXEC_ENV = EXEC_ENV_ENUM.KAGGLE\n",
    "EXEC_ENV = EXEC_ENV_ENUM.LOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sorting and combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 存储提取数据的列表\n",
    "tweets_data = []\n",
    "\n",
    "# 读取 JSON 文件\n",
    "with open('dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # 解析 JSON 每行\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # 提取字段\n",
    "            tweet_id = tweet[\"_source\"][\"tweet\"].get(\"tweet_id\")\n",
    "            text = tweet[\"_source\"][\"tweet\"].get(\"text\")\n",
    "            hashtags = tweet[\"_source\"][\"tweet\"].get(\"hashtags\", [])\n",
    "            crawldate = tweet.get(\"_crawldate\")\n",
    "            score = tweet.get(\"_score\")\n",
    "            index = tweet.get(\"_index\")\n",
    "            doc_type = tweet.get(\"_type\")\n",
    "            \n",
    "            # 衍生字段\n",
    "            hashtag_count = len(hashtags)\n",
    "            text_length = len(text) if text else 0\n",
    "            contains_keyword = \"<LH>\" in text if text else False\n",
    "\n",
    "            # 将提取的字段存入字典，添加到列表\n",
    "            tweets_data.append({\n",
    "                \"tweet_id\": tweet_id,\n",
    "                \"text\": text,\n",
    "                \"hashtags\": hashtags,\n",
    "                \"crawldate\": crawldate,\n",
    "                \"_score\": score,\n",
    "                \"_index\": index,\n",
    "                \"_type\": doc_type,\n",
    "                \"hashtag_count\": hashtag_count,\n",
    "                \"text_length\": text_length,\n",
    "                \"contains_keyword\": contains_keyword\n",
    "            })\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = pd.read_csv('dm-2024-isa-5810-lab-2-homework/data_identification.csv')  # 包含 tweet_id 和 identification\n",
    "emotion = pd.read_csv('dm-2024-isa-5810-lab-2-homework/emotion.csv')  # 包含 tweet_id 和 emotion\n",
    "data = pd.merge(df, classify, on='tweet_id', how='inner')\n",
    "data = pd.merge(data, emotion, on='tweet_id', how='outer')\n",
    "# data # 將情緒特徵及資料分類欄位加入相同dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 data_identification 中 identification 欄位值為 'train' 的選出來作為訓練集\n",
    "train_data = data[data['identification'] == 'train']\n",
    "\n",
    "# 將 identification 欄位值為 'test' 的選出來作為測試集\n",
    "test_data = data[data['identification'] == 'test']\n",
    "\n",
    "# 所有情感emotion in emotion.csv\n",
    "emotions = data['emotion'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "n_splits = 5  # Statified K-Fold 的 fold 數\n",
    "LGBM_Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "    # 'device': 'gpu'\n",
    "}\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": SEED,\n",
    "    # 'tree_method': 'gpu_hist',\n",
    "}\n",
    "CatBoost_Params_original = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "    # 'task_type': 'GPU'\n",
    "}\n",
    "if EXEC_ENV != EXEC_ENV_ENUM.LOCAL:  # Enable GPU\n",
    "    LGBM_Params['device'] = 'gpu'\n",
    "    XGB_Params['tree_method'] = 'gpu_hist'\n",
    "    CatBoost_Params_original['task_type'] = 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## save to pickle file\n",
    "train_data.to_pickle(\"train_data.pkl\") \n",
    "test_data.to_pickle(\"test_data.pkl\")\n",
    "\n",
    "## load a pickle file\n",
    "train_data = pd.read_pickle(\"train_data.pkl\")\n",
    "test_data = pd.read_pickle(\"test_data.pkl\")\n",
    "# already check the size is 411972"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>crawldate</th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_type</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>contains_keyword</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "      <td>242</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "      <td>915</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>12</td>\n",
       "      <td>136</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-07-04 07:22:56</td>\n",
       "      <td>939</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>[Confession, NationalCandyCornDay, CouldEatThe...</td>\n",
       "      <td>2016-04-16 12:53:40</td>\n",
       "      <td>181</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2017-04-22 17:50:28</td>\n",
       "      <td>970</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-12-06 11:10:57</td>\n",
       "      <td>922</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>2015-02-01 18:04:28</td>\n",
       "      <td>77</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>2016-12-20 17:19:58</td>\n",
       "      <td>25</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-09-13 06:31:27</td>\n",
       "      <td>639</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! 😫😱...</td>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>2016-09-19 14:35:01</td>\n",
       "      <td>630</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>tweets</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "1        0x1c7f10   o m g Shut Up And Dance though #BlackMirror <LH>   \n",
       "2        0x1c7f11  On #twitch <LH> on the #Destinybeta #Destiny #...   \n",
       "5        0x1c7f14  A nice sunny wak this morning not many <LH> ar...   \n",
       "6        0x1c7f15  I'm one of those people who love candy corn......   \n",
       "7        0x1c7f16  @metmuseum What are these? They look like some...   \n",
       "...           ...                                                ...   \n",
       "1867529  0x38fe18  @LJPBR @FifthHarmony Um  My vote For @FifthHar...   \n",
       "1867530  0x38fe19     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>   \n",
       "1867531  0x38fe1a  @mattmfm Fake news! <LH> propagated by Tumpkin...   \n",
       "1867533  0x38fe1c                    ..today was brutal  ..#Hungover   \n",
       "1867534  0x38fe1d  Love it when I sun burn my forehead!! NOT!! 😫😱...   \n",
       "\n",
       "                                                  hashtags  \\\n",
       "1                                            [BlackMirror]   \n",
       "2        [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "5                                                       []   \n",
       "6        [Confession, NationalCandyCornDay, CouldEatThe...   \n",
       "7                                                       []   \n",
       "...                                                    ...   \n",
       "1867529                                                 []   \n",
       "1867530                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "1867531                                        [not, maga]   \n",
       "1867533                                                 []   \n",
       "1867534                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                   crawldate  _score          _index   _type  hashtag_count  \\\n",
       "1        2015-05-16 10:36:47     242  hashtag_tweets  tweets              1   \n",
       "2        2016-10-15 20:46:37     915  hashtag_tweets  tweets             12   \n",
       "5        2016-07-04 07:22:56     939  hashtag_tweets  tweets              0   \n",
       "6        2016-04-16 12:53:40     181  hashtag_tweets  tweets              5   \n",
       "7        2017-04-22 17:50:28     970  hashtag_tweets  tweets              0   \n",
       "...                      ...     ...             ...     ...            ...   \n",
       "1867529  2016-12-06 11:10:57     922  hashtag_tweets  tweets              0   \n",
       "1867530  2015-02-01 18:04:28      77  hashtag_tweets  tweets              3   \n",
       "1867531  2016-12-20 17:19:58      25  hashtag_tweets  tweets              2   \n",
       "1867533  2016-09-13 06:31:27     639  hashtag_tweets  tweets              0   \n",
       "1867534  2016-09-19 14:35:01     630  hashtag_tweets  tweets              3   \n",
       "\n",
       "         text_length  contains_keyword identification       emotion  \n",
       "1                 48              True          train           joy  \n",
       "2                136              True          train  anticipation  \n",
       "5                126              True          train           joy  \n",
       "6                135              True          train           joy  \n",
       "7                102              True          train       disgust  \n",
       "...              ...               ...            ...           ...  \n",
       "1867529           83              True          train       sadness  \n",
       "1867530           46              True          train  anticipation  \n",
       "1867531           64              True          train      surprise  \n",
       "1867533           31             False          train       disgust  \n",
       "1867534           89              True          train       sadness  \n",
       "\n",
       "[1455563 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## save to pickle file\n",
    "train_data.to_pickle(\"train_data.pkl\") \n",
    "test_data.to_pickle(\"test_data.pkl\")\n",
    "\n",
    "## load a pickle file\n",
    "train_data = pd.read_pickle(\"train_data.pkl\")\n",
    "test_data = pd.read_pickle(\"test_data.pkl\")\n",
    "train_data # already check the size is 411972"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_data['text'])\n",
    "\n",
    "X_train = BOW_500.transform(train_data['text'])\n",
    "\n",
    "y_train = train_data['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     o m g Shut Up And Dance though #BlackMirror <LH>\n",
      "2    On #twitch <LH> on the #Destinybeta #Destiny #...\n",
      "5    A nice sunny wak this morning not many <LH> ar...\n",
      "6    I'm one of those people who love candy corn......\n",
      "7    @metmuseum What are these? They look like some...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"text\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.543294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 120862\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164450, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score 3.765624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def TrainML(model_class, train_data, test_data):\n",
    "    # 確保文本數據是字符串\n",
    "    train_data[\"text\"] = train_data[\"text\"].astype(str)\n",
    "\n",
    "    # 文本向量化\n",
    "    vectorizer = TfidfVectorizer(max_features=500)  # 可以調整 max_features\n",
    "    X = vectorizer.fit_transform(train_data[\"text\"]).toarray()\n",
    "\n",
    "    # 標籤編碼\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(train_data[\"emotion\"])\n",
    "\n",
    "    \"\"\"\n",
    "    使用 Stratified K-Fold 分層抽樣確保各類別比例一致\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # 模型訓練\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # 克隆模型並訓練\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Validation Score:\", model.score(X_val, y_val))\n",
    "\n",
    "    # 使用整個訓練集進行最終模型訓練\n",
    "    model_class.fit(X, y)\n",
    "\n",
    "    # 測試集預測\n",
    "    test_data[\"text\"] = test_data[\"text\"].astype(str)\n",
    "    X_test = vectorizer.transform(test_data[\"text\"]).toarray()\n",
    "    return model_class.predict(X_test)\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 初始化基礎模型\n",
    "Light = LGBMRegressor()\n",
    "XGBoost = XGBRegressor()\n",
    "RandomForest = RandomForestRegressor()\n",
    "\n",
    "# 定義投票回歸模型\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        (\"lightgbm\", Light),\n",
    "        (\"xgboost\", XGBoost),\n",
    "        (\"randomforest\", RandomForest),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Submission1 = TrainML(voting_model, train_data, test_data)\n",
    "print(\"Submission:\", Submission1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.697855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2304\n",
      "[LightGBM] [Info] Number of data points in the train set: 1455563, number of used features: 500\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765956\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037008\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957809\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 定义 LightGBM 模型\n",
    "model = LGBMClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 测试集预测\n",
    "y_test_pred_lgbm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 定义 CatBoostClassifier 模型\n",
    "model = CatBoostClassifier(iterations=300, random_state=42, verbose=0)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 测试集预测\n",
    "\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 测试集预测\n",
    "y_test_pred_rf = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预测结果\n",
    "test_data[\"emotion\"] = y_test_pred_rf\n",
    "test_data[[\"tweet_id\", \"emotion\"]].to_csv(\"test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
